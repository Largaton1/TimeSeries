{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPC - TP - Prediction by regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>-1.7101</td>\n",
       "      <td>-0.6946</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-3.0000</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>15.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.9544</td>\n",
       "      <td>1.8794</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>16.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>-0.1736</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>17.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-2.9544</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>84</td>\n",
       "      <td>13.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.2856</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>77</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.6946</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>-1.3681</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>16.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>83</td>\n",
       "      <td>16.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-3.7588</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>70</td>\n",
       "      <td>15.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0419</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y    x1    x2    x3  x4  x5  x6      x7      x8      x9  x10\n",
       "0     87  15.6  18.5  18.4   4   4   8  0.6946 -1.7101 -0.6946   84\n",
       "1     82  17.0  18.4  17.7   5   5   7 -4.3301 -4.0000 -3.0000   87\n",
       "2     92  15.3  17.6  19.5   2   5   4  2.9544  1.8794  0.5209   82\n",
       "3    114  16.2  19.7  22.5   1   1   0  0.9848  0.3473 -0.1736   92\n",
       "4     94  17.4  20.5  20.4   8   8   7 -0.5000 -2.9544 -4.3301  114\n",
       "..   ...   ...   ...   ...  ..  ..  ..     ...     ...     ...  ...\n",
       "96    84  13.3  17.7  17.8   3   5   6  0.0000 -1.0000 -1.2856   76\n",
       "97    77  16.2  20.8  22.1   6   5   5 -0.6946 -2.0000 -1.3681   71\n",
       "98    99  16.9  23.0  22.6   6   4   7  1.5000  0.8682  0.8682   77\n",
       "99    83  16.9  19.8  22.1   6   5   3 -4.0000 -3.7588 -4.0000   99\n",
       "100   70  15.7  18.6  20.7   7   7   7  0.0000 -1.0419 -4.0000   83\n",
       "\n",
       "[101 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "ozone = pd.read_csv('ozone.txt', sep = ' ')\n",
    "ozone\n",
    "# y is the target variable, the other are predictive variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Question : How many examples are there in this dataset ? How many variables (including the target one) describe them ?\n",
    "Nous avons: 101 exemples et 11 variables (dont la variable cible)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This dataset represents some meteorological information taken at different days during different periods.\n",
    " - y represents the maximal ozone (O3) concentration in the air during a given day\n",
    " - x1, x2, x3 are the temperatures at 9am, 12am, and 3pm during the same day\n",
    " - x4, x5, x6 represent the cloudiness at 9am, 12am, and 3pm during the same day\n",
    " - x7, x8, x9 represent the wind projected on the axis East-West at 9am, 12am, and 3pm during the same day\n",
    " - x10 is the maximal ozone (O3) concentration in the air during the day before.\n",
    " \n",
    "In this TP, we aim at predicting y using one or more of the available predictive variables (x1 to x10).\n",
    "We will apply the different techniques seen during the course to evaluate different regression models and try to choose the most adapted one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 : Simple linear regression to predict y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this exercice, we will assume that we can only use one variable to predict y. Our objective is to find which variable is the best one for that.\n",
    "We will start by considering x1 to predict y."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : Draw a plot to visualize the relationship between x1 (x-axis) and y (y-axis)\n",
    "Add a title, and labels for the axes.\n",
    "Hint : We want to visualize the points in a 2D graph (no line between the points).\n",
    "plt.scatter makes the job, or plt.plot but with 'o' as parameter to indicate that we want only the points (no lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ozone['x1'], ozone['y'])\n",
    "plt.title('Relationship between x1 and y')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : Do you think that a regression model can help here to predict y using x1 ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Oui, un modÃ¨le de rÃ©gression peut potentiellement aider Ã  prÃ©dire y en utilisant x1. En observant la relation entre x1 et y (comme dans le graphique tracÃ© prÃ©cÃ©demment), si une tendance linÃ©aire ou une corrÃ©lation significative est visible, cela indique que x1 a une influence sur y. Cependant, il est important de vÃ©rifier statistiquement cette relation Ã  l'aide des coefficients, des tests de Student, et des valeurs p pour confirmer si x1 est un bon prÃ©dicteur de y. Si la relation est faible ou inexistante, un modÃ¨le de rÃ©gression basÃ© uniquement sur x1 ne sera pas efficace."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will now create a regression model with y as target variable and x1 as predictive variable.\n",
    "For that, there are different possibilities in Python. We will use here the OLS function of the statsmodel package.\n",
    "It works like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     const    x1\n",
      "0      1.0  15.6\n",
      "1      1.0  17.0\n",
      "2      1.0  15.3\n",
      "3      1.0  16.2\n",
      "4      1.0  17.4\n",
      "..     ...   ...\n",
      "96     1.0  13.3\n",
      "97     1.0  16.2\n",
      "98     1.0  16.9\n",
      "99     1.0  16.9\n",
      "100    1.0  15.7\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   105.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 09 Apr 2025</td> <th>  Prob (F-statistic):</th> <td>2.78e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:00:23</td>     <th>  Log-Likelihood:    </th> <td> -444.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   101</td>      <th>  AIC:               </th> <td>   893.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    99</td>      <th>  BIC:               </th> <td>   898.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  -33.0106</td> <td>   12.221</td> <td>   -2.701</td> <td> 0.008</td> <td>  -57.259</td> <td>   -8.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    6.7460</td> <td>    0.657</td> <td>   10.273</td> <td> 0.000</td> <td>    5.443</td> <td>    8.049</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.779</td> <th>  Durbin-Watson:     </th> <td>   0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.249</td> <th>  Jarque-Bera (JB):  </th> <td>   2.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.360</td> <th>  Prob(JB):          </th> <td>   0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.163</td> <th>  Cond. No.          </th> <td>    115.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.516   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.511   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     105.5   \\\\\n",
       "\\textbf{Date:}             & Wed, 09 Apr 2025 & \\textbf{  Prob (F-statistic):} &  2.78e-17   \\\\\n",
       "\\textbf{Time:}             &     16:00:23     & \\textbf{  Log-Likelihood:    } &   -444.69   \\\\\n",
       "\\textbf{No. Observations:} &         101      & \\textbf{  AIC:               } &     893.4   \\\\\n",
       "\\textbf{Df Residuals:}     &          99      & \\textbf{  BIC:               } &     898.6   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &     -33.0106  &       12.221     &    -2.701  &         0.008        &      -57.259    &       -8.762     \\\\\n",
       "\\textbf{x1}    &       6.7460  &        0.657     &    10.273  &         0.000        &        5.443    &        8.049     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.779 & \\textbf{  Durbin-Watson:     } &    0.900  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.249 & \\textbf{  Jarque-Bera (JB):  } &    2.289  \\\\\n",
       "\\textbf{Skew:}          &  0.360 & \\textbf{  Prob(JB):          } &    0.318  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.163 & \\textbf{  Cond. No.          } &     115.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.516\n",
       "Model:                            OLS   Adj. R-squared:                  0.511\n",
       "Method:                 Least Squares   F-statistic:                     105.5\n",
       "Date:                Wed, 09 Apr 2025   Prob (F-statistic):           2.78e-17\n",
       "Time:                        16:00:23   Log-Likelihood:                -444.69\n",
       "No. Observations:                 101   AIC:                             893.4\n",
       "Df Residuals:                      99   BIC:                             898.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -33.0106     12.221     -2.701      0.008     -57.259      -8.762\n",
       "x1             6.7460      0.657     10.273      0.000       5.443       8.049\n",
       "==============================================================================\n",
       "Omnibus:                        2.779   Durbin-Watson:                   0.900\n",
       "Prob(Omnibus):                  0.249   Jarque-Bera (JB):                2.289\n",
       "Skew:                           0.360   Prob(JB):                        0.318\n",
       "Kurtosis:                       3.163   Cond. No.                         115.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = ozone['x1'] # Select the column containing the predictive variable\n",
    "X = sm.add_constant(X) # add a constant column for the constant term of the model (for the parameter beta_0)\n",
    "print(X) # you should see 2 columns in X : a constant one (const) with ones everywhere and another with the values of x1\n",
    "Y = ozone['y'] # Select the target variable and store it in Y\n",
    "model = sm.OLS(Y, X).fit() # fit the model to predict Y using X\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You can see above a lot of informations about the created model. The things that we need are : \n",
    "    - the coefficients of the model : in the column 'coef'. 2 coefficients here (beta0 for const and beta1 for x1). You can access them by model.params\n",
    "    - the uncertainty about the estimation of the coefficient : column 'std err'. We are only interested in the one for beta_1. You can access them by model.bse\n",
    "    - the value of the student's test about x1 : in the column 't'. You can access it by model.tvalues\n",
    "    - the critical probability of the student's test about x1 : column 'P>|t|'. You can access it by model.pvalues"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Questions : \n",
    " - What is the equation of the model ?\n",
    " - What can you conclude about the influence of x1 on y ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equation of the model is: y = -33.01 + 6.75 * x1\n",
      "x1 has a statistically significant influence on y.\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficients\n",
    "beta_0 = model.params['const']  # Intercept\n",
    "beta_1 = model.params['x1']     # Coefficient for x1\n",
    "\n",
    "# Equation of the model\n",
    "print(f\"The equation of the model is: y = {beta_0:.2f} + {beta_1:.2f} * x1\")\n",
    "\n",
    "# Analyze the influence of x1 on y\n",
    "p_value = model.pvalues['x1']\n",
    "if p_value < 0.05:\n",
    "    print(\"x1 has a statistically significant influence on y.\")\n",
    "else:\n",
    "    print(\"x1 does not have a statistically significant influence on y.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Questions: \n",
    " - What should be the prediction made by the model for the first individual of the ozone dataset ? (index 0)\n",
    " - What is the residual (error) for this individual ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the first individual: 72.23\n",
      "Residual for the first individual: 14.77\n"
     ]
    }
   ],
   "source": [
    "# Prediction for the first individual\n",
    "x1_first = ozone.loc[0, 'x1']  # x1 value for the first individual\n",
    "prediction_first = beta_0 + beta_1 * x1_first\n",
    "print(f\"Prediction for the first individual: {prediction_first:.2f}\")\n",
    "\n",
    "# Residual (error) for the first individual\n",
    "actual_first = ozone.loc[0, 'y']  # Actual y value for the first individual\n",
    "residual_first = actual_first - prediction_first\n",
    "print(f\"Residual for the first individual: {residual_first:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      72.226485\n",
       "1      81.670840\n",
       "2      70.202695\n",
       "3      76.274066\n",
       "4      84.369227\n",
       "         ...    \n",
       "96     56.710759\n",
       "97     76.274066\n",
       "98     80.996243\n",
       "99     80.996243\n",
       "100    72.901082\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the predictions made by the model on the dataset used to fit the model can be accessed by\n",
    "model.fittedvalues\n",
    "# Check that the fitted value for the first individual is equal to the one you computed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      14.773515\n",
       "1       0.329160\n",
       "2      21.797305\n",
       "3      37.725934\n",
       "4       9.630773\n",
       "         ...    \n",
       "96     27.289241\n",
       "97      0.725934\n",
       "98     18.003757\n",
       "99      2.003757\n",
       "100    -2.901082\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the residuals made by the model on the dataset used to fit the model can be accessed by\n",
    "model.resid\n",
    "# Check that the residual for the first individual is equal to the one you computed above"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : Plot on the same graph the data (y VS x1, as before) and the regression model (the fitted values define the regression line). Add labels to the axis and a legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot for the data\n",
    "plt.scatter(ozone['x1'], ozone['y'], label='Data', color='blue')\n",
    "\n",
    "# Regression line\n",
    "plt.plot(ozone['x1'], model.fittedvalues, label='Regression Line', color='red')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('y')\n",
    "plt.title('Data and Regression Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have seen in the CM two important quantities related to a regression model : the coefficient of determination (R^2) and I_r, the sum of squared residuals (residuals are errors made by the model on the data used to create it).\n",
    "The R^2 can be obtained by model.rsquared \n",
    "The residuals can be obtained by model.resid as explained before"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Questions : \n",
    " - What is the R^2 of this model ?\n",
    " - Compute I_r\n",
    " - Compute I_t according to the formula in the slides. (you can use np.sum() and np.mean())\n",
    " - Deduce I_m \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of the model: 0.5160\n",
      "I_r (sum of squared residuals): 39455.8049\n",
      "I_t (total sum of squares): 81516.0594\n",
      "I_m (explained sum of squares): 42060.2545\n"
     ]
    }
   ],
   "source": [
    "# R^2 of the model\n",
    "r_squared = model.rsquared\n",
    "print(f\"R^2 of the model: {r_squared:.4f}\")\n",
    "\n",
    "# Compute I_r (sum of squared residuals)\n",
    "I_r = np.sum(model.resid ** 2)\n",
    "print(f\"I_r (sum of squared residuals): {I_r:.4f}\")\n",
    "\n",
    "# Compute I_t (total sum of squares)\n",
    "y_mean = np.mean(Y)\n",
    "I_t = np.sum((Y - y_mean) ** 2)\n",
    "print(f\"I_t (total sum of squares): {I_t:.4f}\")\n",
    "\n",
    "# Deduce I_m (explained sum of squares)\n",
    "I_m = I_t - I_r\n",
    "print(f\"I_m (explained sum of squares): {I_m:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To compare models with one predictive variable, we can use :\n",
    " - R^2 (higher is better)\n",
    " - I_r (lower is better)\n",
    " - the critical probability of the student's test on the predictive variable (lower is better)\n",
    "We have seen how to get these 3 quantities.\n",
    "We will now try another simple regression model (with another predictive variable) and compare these quantities."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : Compute these quantities for a simple regression model that predicts y using x4. Which variable (x1 or x4) seems more adpated to predict y ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of the model using x4: 0.3782\n",
      "I_r (sum of squared residuals) using x4: 50688.4199\n",
      "I_t (total sum of squares): 81516.0594\n",
      "I_m (explained sum of squares) using x4: 30827.6395\n",
      "P-value for x4: 7.8310e-12\n",
      "\n",
      "Comparaison:\n",
      "x1 has a higher R^2 and is better at explaining the variance in y.\n",
      "x1 has a lower I_r and is better at minimizing residuals.\n",
      "x1 has a lower p-value and is more statistically significant.\n"
     ]
    }
   ],
   "source": [
    "# Create the regression model for y using x4\n",
    "X_x4 = ozone['x4']  # Select x4 as the predictive variable\n",
    "X_x4 = sm.add_constant(X_x4)  # Add a constant column\n",
    "Y = ozone['y']  # Target variable\n",
    "model_x4 = sm.OLS(Y, X_x4).fit()  # Fit the model\n",
    "\n",
    "# Extract R^2\n",
    "r_squared_x4 = model_x4.rsquared\n",
    "print(f\"R^2 of the model using x4: {r_squared_x4:.4f}\")\n",
    "\n",
    "# Compute I_r (sum of squared residuals)\n",
    "I_r_x4 = np.sum(model_x4.resid ** 2)\n",
    "print(f\"I_r (sum of squared residuals) using x4: {I_r_x4:.4f}\")\n",
    "\n",
    "# Compute I_t (total sum of squares)\n",
    "I_t_x4 = np.sum((Y - y_mean) ** 2)\n",
    "print(f\"I_t (total sum of squares): {I_t_x4:.4f}\")\n",
    "\n",
    "# Deduce I_m (explained sum of squares)\n",
    "I_m_x4 = I_t_x4 - I_r_x4\n",
    "print(f\"I_m (explained sum of squares) using x4: {I_m_x4:.4f}\")\n",
    "\n",
    "# Extract p-value for x4\n",
    "p_value_x4 = model_x4.pvalues['x4']\n",
    "print(f\"P-value for x4: {p_value_x4:.4e}\")\n",
    "\n",
    "# Compare x1 and x4\n",
    "print(\"\\nComparaison:\")\n",
    "if r_squared > r_squared_x4:\n",
    "    print(\"x1 has a higher R^2 and is better at explaining the variance in y.\")\n",
    "else:\n",
    "    print(\"x4 has a higher R^2 and is better at explaining the variance in y.\")\n",
    "\n",
    "if I_r < I_r_x4:\n",
    "    print(\"x1 has a lower I_r and is better at minimizing residuals.\")\n",
    "else:\n",
    "    print(\"x4 has a lower I_r and is better at minimizing residuals.\")\n",
    "\n",
    "if p_value < p_value_x4:\n",
    "    print(\"x1 has a lower p-value and is more statistically significant.\")\n",
    "else:\n",
    "    print(\"x4 has a lower p-value and is more statistically significant.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : Select, according to these 3 criteria, the best variable (amongst the 10 predictive ones) to predict y.\n",
    "Hint : you can use a 'for' loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best variable: x2\n",
      "R^2: 0.6129\n",
      "I_r: 31555.3095\n",
      "P-value: 4.0198e-22\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store the best variable and its metrics\n",
    "best_variable = None\n",
    "best_r_squared = -float('inf')  # Higher is better\n",
    "best_I_r = float('inf')         # Lower is better\n",
    "best_p_value = float('inf')     # Lower is better\n",
    "\n",
    "# Loop through all predictive variables\n",
    "for i in range(1, 11):  # x1 to x10\n",
    "    X_var = ozone[f'x{i}']  # Select the current variable\n",
    "    X_var = sm.add_constant(X_var)  # Add a constant column\n",
    "    model_var = sm.OLS(Y, X_var).fit()  # Fit the model\n",
    "    \n",
    "    # Extract metrics\n",
    "    r_squared_var = model_var.rsquared\n",
    "    I_r_var = np.sum(model_var.resid ** 2)\n",
    "    p_value_var = model_var.pvalues[f'x{i}']\n",
    "    \n",
    "    # Compare and update the best variable\n",
    "    if (r_squared_var > best_r_squared or\n",
    "        (r_squared_var == best_r_squared and I_r_var < best_I_r) or\n",
    "        (r_squared_var == best_r_squared and I_r_var == best_I_r and p_value_var < best_p_value)):\n",
    "        best_variable = f'x{i}'\n",
    "        best_r_squared = r_squared_var\n",
    "        best_I_r = I_r_var\n",
    "        best_p_value = p_value_var\n",
    "\n",
    "# Print the best variable and its metrics\n",
    "print(f\"Best variable: {best_variable}\")\n",
    "print(f\"R^2: {best_r_squared:.4f}\")\n",
    "print(f\"I_r: {best_I_r:.4f}\")\n",
    "print(f\"P-value: {best_p_value:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we will see how this best model behaves when predicting new data, and compare with the first model that we have tried (using x1). For this, we will 'cheat' (but we'll do it in a more proper way a bit later) : you will find\n",
    "10 new individuals in the file 'ozone_n.txt'. For these 10 new individuals, we have the values of the 10 predictive variables and also the value of the target variable. In a real prediction setting, you will never have new individuals with the ground truth (values of the target variable), but here we will do like that to start. We can consider that these new individuals are our test set. In a latter exercice, I will show you how to do a proper train / test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>18.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1.2856</td>\n",
       "      <td>-2.2981</td>\n",
       "      <td>-3.9392</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.2139</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>19.9</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>-3.0000</td>\n",
       "      <td>-4.5963</td>\n",
       "      <td>-5.1962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>18.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>23.9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.5981</td>\n",
       "      <td>-3.9392</td>\n",
       "      <td>-3.7588</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97</td>\n",
       "      <td>20.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.7101</td>\n",
       "      <td>-2.7362</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.9392</td>\n",
       "      <td>-1.9284</td>\n",
       "      <td>-1.7101</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>-7.8785</td>\n",
       "      <td>-5.1962</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81</td>\n",
       "      <td>19.6</td>\n",
       "      <td>25.1</td>\n",
       "      <td>27.2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.9284</td>\n",
       "      <td>-2.5712</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>146</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9544</td>\n",
       "      <td>6.5778</td>\n",
       "      <td>4.3301</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78</td>\n",
       "      <td>17.7</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y    x1    x2    x3  x4  x5  x6      x7      x8      x9  x10\n",
       "0  106  18.3  21.9  22.9   5   6   8  1.2856 -2.2981 -3.9392  101\n",
       "1   60  13.7  14.0  15.8   4   5   4  0.0000  3.2139  0.0000   71\n",
       "2   72  19.9  21.6  20.4   7   7   8 -3.0000 -4.5963 -5.1962   65\n",
       "3   72  18.1  21.2  23.9   7   6   4 -2.5981 -3.9392 -3.7588  113\n",
       "4   97  20.8  23.7  25.0   2   3   4  0.0000  1.7101 -2.7362   93\n",
       "5   59  18.3  18.3  19.0   7   7   7 -3.9392 -1.9284 -1.7101   66\n",
       "6   70  17.1  18.2  18.0   7   7   7 -4.3301 -7.8785 -5.1962   72\n",
       "7   81  19.6  25.1  27.2   3   4   4 -1.9284 -2.5712 -4.3301   57\n",
       "8  146  27.0  32.7  33.7   0   0   0  2.9544  6.5778  4.3301  121\n",
       "9   78  17.7  20.2  21.5   5   5   3  0.0000  0.5209  0.0000   59"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load these new individuals.\n",
    "ozone_new = pd.read_csv('ozone_n.txt', sep = ' ')\n",
    "ozone_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     90.440598\n",
       "1     59.409146\n",
       "2    101.234147\n",
       "3     89.091404\n",
       "4    107.305518\n",
       "5     90.440598\n",
       "6     82.345437\n",
       "7     99.210356\n",
       "8    149.130518\n",
       "9     86.393017\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I show you here how to predict the values of new data using a model\n",
    "# First, we will fit a model to predict y using x1 with the ozone data as before (we don't use the new individuals to fit the model)\n",
    "X = ozone.iloc[:,1] \n",
    "X = sm.add_constant(X) \n",
    "Y = ozone['y']\n",
    "model = sm.OLS(Y, X).fit() \n",
    "# Then, we will prepare the new data so that it is under the same form as the data used to create the model,\n",
    "# i.e. one constant column and one column with x1 values for the new data\n",
    "X_new = ozone_new.iloc[:,1] # only the x1 column of the new dataset\n",
    "X_new = sm.add_constant(X_new) # add the constant column\n",
    "# and then we can easily predict y for this new dataset:\n",
    "model.predict(X_new)\n",
    "# You can see the predictions for the 10 individuals of ozone_new"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : What is the mean squared error of these predictions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of the predictions: 304.8180\n"
     ]
    }
   ],
   "source": [
    "# Predictions for the new dataset using the model\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Actual values from the new dataset\n",
    "actual_values = ozone_new['y']\n",
    "\n",
    "# Compute the mean squared error\n",
    "mse = np.mean((actual_values - predictions) ** 2)\n",
    "print(f\"Mean Squared Error of the predictions: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : Do the same for the best model that you found above, and compare the mean squared errors of the 2 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of the best model (x2): 2161.2276\n",
      "The model using x1 has a lower MSE and performs better.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the new data for the best model (using x2)\n",
    "X_new_best = ozone_new[['x2']]  # Select x2 as the predictive variable\n",
    "X_new_best = sm.add_constant(X_new_best)  # Add a constant column\n",
    "\n",
    "# Predict using the best model\n",
    "predictions_best = model_var.predict(X_new_best)\n",
    "\n",
    "# Compute the mean squared error for the best model\n",
    "mse_best = np.mean((actual_values - predictions_best) ** 2)\n",
    "print(f\"Mean Squared Error of the best model (x2): {mse_best:.4f}\")\n",
    "\n",
    "# Compare the MSEs\n",
    "if mse < mse_best:\n",
    "    print(\"The model using x1 has a lower MSE and performs better.\")\n",
    "else:\n",
    "    print(\"The model using x2 has a lower MSE and performs better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Multiple regression to predict y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will now apply multiple regression (more than one predictive variable) to predict y. To perform multiple regression, we can use the OLS function as before but we just need to put more variables in the X dataframe used as input to OLS.\n",
    "For instance, below we will create a model to predict y using x2 and x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   78.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 09 Apr 2025</td> <th>  Prob (F-statistic):</th> <td>4.62e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:40:29</td>     <th>  Log-Likelihood:    </th> <td> -433.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   101</td>      <th>  AIC:               </th> <td>   872.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   880.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  -33.8288</td> <td>   10.950</td> <td>   -3.089</td> <td> 0.003</td> <td>  -55.558</td> <td>  -12.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.0269</td> <td>    1.279</td> <td>    0.803</td> <td> 0.424</td> <td>   -1.512</td> <td>    3.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    4.9153</td> <td>    0.976</td> <td>    5.034</td> <td> 0.000</td> <td>    2.978</td> <td>    6.853</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.676</td> <th>  Durbin-Watson:     </th> <td>   0.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.713</td> <th>  Jarque-Bera (JB):  </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.163</td> <th>  Prob(JB):          </th> <td>   0.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.708</td> <th>  Cond. No.          </th> <td>    177.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.615   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.608   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     78.41   \\\\\n",
       "\\textbf{Date:}             & Wed, 09 Apr 2025 & \\textbf{  Prob (F-statistic):} &  4.62e-21   \\\\\n",
       "\\textbf{Time:}             &     10:40:29     & \\textbf{  Log-Likelihood:    } &   -433.07   \\\\\n",
       "\\textbf{No. Observations:} &         101      & \\textbf{  AIC:               } &     872.1   \\\\\n",
       "\\textbf{Df Residuals:}     &          98      & \\textbf{  BIC:               } &     880.0   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &     -33.8288  &       10.950     &    -3.089  &         0.003        &      -55.558    &      -12.100     \\\\\n",
       "\\textbf{x1}    &       1.0269  &        1.279     &     0.803  &         0.424        &       -1.512    &        3.566     \\\\\n",
       "\\textbf{x2}    &       4.9153  &        0.976     &     5.034  &         0.000        &        2.978    &        6.853     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.676 & \\textbf{  Durbin-Watson:     } &    0.980  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.713 & \\textbf{  Jarque-Bera (JB):  } &    0.806  \\\\\n",
       "\\textbf{Skew:}          &  0.163 & \\textbf{  Prob(JB):          } &    0.668  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.708 & \\textbf{  Cond. No.          } &     177.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.615\n",
       "Model:                            OLS   Adj. R-squared:                  0.608\n",
       "Method:                 Least Squares   F-statistic:                     78.41\n",
       "Date:                Wed, 09 Apr 2025   Prob (F-statistic):           4.62e-21\n",
       "Time:                        10:40:29   Log-Likelihood:                -433.07\n",
       "No. Observations:                 101   AIC:                             872.1\n",
       "Df Residuals:                      98   BIC:                             880.0\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -33.8288     10.950     -3.089      0.003     -55.558     -12.100\n",
       "x1             1.0269      1.279      0.803      0.424      -1.512       3.566\n",
       "x2             4.9153      0.976      5.034      0.000       2.978       6.853\n",
       "==============================================================================\n",
       "Omnibus:                        0.676   Durbin-Watson:                   0.980\n",
       "Prob(Omnibus):                  0.713   Jarque-Bera (JB):                0.806\n",
       "Skew:                           0.163   Prob(JB):                        0.668\n",
       "Kurtosis:                       2.708   Cond. No.                         177.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ozone.iloc[:,[1,2]] # select columns of index 1 and 2 (i.e. x1 and x2)\n",
    "X = sm.add_constant(X)\n",
    "Y = ozone['y']\n",
    "model = sm.OLS(Y,X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Questions : \n",
    "    - What is the equation of the model ?\n",
    "    - What is the result of the Student's test on x1 ? What does it mean ?\n",
    "    - What is the R^2 of this model ? Compare it with the model where x2 is alone to predict y. Conclusion\n",
    "    - What is I_r for this model ? Compare it with the model where x2 is alone to predict y. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equation of the model\n",
    "beta_0 = model.params['const']  # Intercept\n",
    "beta_1 = model.params['x1']     # Coefficient for x1\n",
    "beta_2 = model.params['x2']     # Coefficient for x2\n",
    "print(f\"The equation of the model is: y = {beta_0:.2f} + {beta_1:.2f} * x1 + {beta_2:.2f} * x2\")\n",
    "\n",
    "# Result of the Student's test on x1\n",
    "p_value_x1 = model.pvalues['x1']\n",
    "print(f\"Student's test p-value for x1: {p_value_x1:.4e}\")\n",
    "if p_value_x1 < 0.05:\n",
    "    print(\"x1 has a statistically significant influence on y.\")\n",
    "else:\n",
    "    print(\"x1 does not have a statistically significant influence on y.\")\n",
    "\n",
    "# R^2 of the model\n",
    "r_squared_combined = model.rsquared\n",
    "print(f\"R^2 of the model: {r_squared_combined:.4f}\")\n",
    "print(f\"R^2 of the model using x2 alone: {best_r_squared:.4f}\")\n",
    "if r_squared_combined > best_r_squared:\n",
    "    print(\"The combined model (x1 and x2) explains more variance in y than the model using x2 alone.\")\n",
    "else:\n",
    "    print(\"The model using x2 alone explains more variance in y than the combined model (x1 and x2).\")\n",
    "\n",
    "# I_r for the model\n",
    "I_r_combined = np.sum(model.resid ** 2)\n",
    "print(f\"I_r of the model: {I_r_combined:.4f}\")\n",
    "print(f\"I_r of the model using x2 alone: {best_I_r:.4f}\")\n",
    "if I_r_combined < best_I_r:\n",
    "    print(\"The combined model (x1 and x2) has lower residual error than the model using x2 alone.\")\n",
    "else:\n",
    "    print(\"The model using x2 alone has lower residual error than the combined model (x1 and x2).\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question : Use this model to predict the 10 new individuals (of the ozone_new dataset) and compute the mean square prediction error. Conclusion ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Prediction Error of the combined model (x1 and x2): 225.9460\n",
      "The combined model (x1 and x2) performs better than the model using x2 alone.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the new data for the model (using x1 and x2)\n",
    "X_new_combined = ozone_new[['x1', 'x2']]  # Select x1 and x2 as predictive variables\n",
    "X_new_combined = sm.add_constant(X_new_combined)  # Add a constant column\n",
    "\n",
    "# Predict using the combined model\n",
    "predictions_combined = model.predict(X_new_combined)\n",
    "\n",
    "# Compute the mean squared prediction error for the combined model\n",
    "mse_combined = np.mean((ozone_new['y'] - predictions_combined) ** 2)\n",
    "print(f\"Mean Squared Prediction Error of the combined model (x1 and x2): {mse_combined:.4f}\")\n",
    "\n",
    "# Conclusion\n",
    "if mse_combined < mse_best:\n",
    "    print(\"The combined model (x1 and x2) performs better than the model using x2 alone.\")\n",
    "else:\n",
    "    print(\"The model using x2 alone performs better than the combined model (x1 and x2).\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You should conclude that the model with x1 and x2 is worse than x2 alone (to predict these new individuals), but the R^2 and I_r said that x1 and x2 is better than x2 alone.\n",
    "This is the problem I explained in the CM : R^2 and I_r are always in favor of models with more variables (even if you add variables completely independant of the target variable) and they do not ensure that a model will be good to predict new indiviuals.\n",
    "That's why a better criterion is the estimation of the generalization error. \n",
    "In the next exercice, we will apply the train / test split strategy to estimate this generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 : Estimation of the generalization error by train / test split."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before going with the train/test split, I advice you to create two functions that might help you with easily creating regression models and computing predictions.\n",
    "1) Define a function 'my_regression(data, idx_p, idx_t)'. The aim of this function is to create, using a dataset 'data', a regression model to predict the variable whose column index is 'idx_t' (index target) using the variables whose column indexes are in 'idx_p' (index predictive). \n",
    "For instance, the call my_regression(ozone, [2], 0)' should create the model to predict y (column 0 of ozone) using x2 (column 2 of ozone).\n",
    "And the call my_regression(ozone, [1,2], 0) should create the model to predict y (column 0 of ozone) using x1 and x2 (columns 1 and 2 of ozone).\n",
    "You have already done this kind of things you just have to wrap everything up in a function. The idea of this function is to have a simple ang generic way to create different models, without having to create the X, add a constant, create the Y and call the OLS each time you need to fit a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def my_regression(data, idx_p, idx_t):\n",
    "    \"\"\"\n",
    "    Create a regression model to predict the target variable using specified predictive variables.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The dataset containing the variables.\n",
    "    idx_p (list): List of column indexes for predictive variables.\n",
    "    idx_t (int): Column index for the target variable.\n",
    "\n",
    "    Returns:\n",
    "    statsmodels.regression.linear_model.RegressionResultsWrapper: The fitted regression model.\n",
    "    \"\"\"\n",
    "    # Select predictive variables and add a constant column\n",
    "    X = data.iloc[:, idx_p]\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Select the target variable\n",
    "    Y = data.iloc[:, idx_t]\n",
    "    \n",
    "    # Fit the regression model\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2) Create a function 'my_prediction(my_model, data)' that returns the predictions made by the model 'my_model'\n",
    "for the individuals of the dataset 'data'. \n",
    "Be careful, you need to select the columns of the dataset 'data' that the model 'my_model' needs (i.e. the ones that were used to create the model).\n",
    "For that, you can find the names of the predictive variables of 'my_model' by the command my_model.model.exog_names, and then you have to select the columns having these names (by a .loc on data)\n",
    "Don't forget to add a constant to the data before the predictions (as in the exemple a few cells above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_prediction(my_model, data):\n",
    "    \"\"\"\n",
    "    Generate predictions using the given regression model for the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "    my_model (statsmodels.regression.linear_model.RegressionResultsWrapper): The regression model.\n",
    "    data (pd.DataFrame): The dataset containing the variables.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Predictions made by the model.\n",
    "    \"\"\"\n",
    "    # Get the names of the predictive variables used in the model\n",
    "    predictive_vars = my_model.model.exog_names\n",
    "    \n",
    "    # Select the corresponding columns from the dataset\n",
    "    # Ensure to exclude 'const' as it is added separately\n",
    "    if 'const' in predictive_vars:\n",
    "        predictive_vars.remove('const')\n",
    "    X_new = data.loc[:, predictive_vars]\n",
    "    \n",
    "    # Add a constant column to the dataset\n",
    "    X_new = sm.add_constant(X_new)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = my_model.predict(X_new)\n",
    "    \n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3) Try to use your functions to create a regression model using ozone (with predictive variables of your choice) and then use this model to predict the individuals of ozone_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for ozone_new using x2 and x3:\n",
      "0     92.662833\n",
      "1     50.977049\n",
      "2     86.655888\n",
      "3     92.200491\n",
      "4    103.117455\n",
      "5     72.348636\n",
      "6     70.015739\n",
      "7    112.372807\n",
      "8    151.820282\n",
      "9     83.946060\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a regression model using x2 and x3 as predictive variables\n",
    "model_x2_x3 = my_regression(ozone, [2, 3], 0)\n",
    "\n",
    "# Use the model to predict the individuals of ozone_new\n",
    "predictions_ozone_new = my_prediction(model_x2_x3, ozone_new)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions for ozone_new using x2 and x3:\")\n",
    "print(predictions_ozone_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4) Now we will see how to do a train / test split to estimate the generalization error of a regression model.\n",
    "First we will combine our two datasets (ozone and ozone_new in a single one). In a real prediction setting, you'll get one complete dataset (with predictive variables and a target one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>-1.7101</td>\n",
       "      <td>-0.6946</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>-3.0000</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>15.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.9544</td>\n",
       "      <td>1.8794</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>16.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>-0.1736</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>17.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-2.9544</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>59</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.9392</td>\n",
       "      <td>-1.9284</td>\n",
       "      <td>-1.7101</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>70</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>-7.8785</td>\n",
       "      <td>-5.1962</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>81</td>\n",
       "      <td>19.6</td>\n",
       "      <td>25.1</td>\n",
       "      <td>27.2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.9284</td>\n",
       "      <td>-2.5712</td>\n",
       "      <td>-4.3301</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9544</td>\n",
       "      <td>6.5778</td>\n",
       "      <td>4.3301</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>78</td>\n",
       "      <td>17.7</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y    x1    x2    x3  x4  x5  x6      x7      x8      x9  x10\n",
       "0     87  15.6  18.5  18.4   4   4   8  0.6946 -1.7101 -0.6946   84\n",
       "1     82  17.0  18.4  17.7   5   5   7 -4.3301 -4.0000 -3.0000   87\n",
       "2     92  15.3  17.6  19.5   2   5   4  2.9544  1.8794  0.5209   82\n",
       "3    114  16.2  19.7  22.5   1   1   0  0.9848  0.3473 -0.1736   92\n",
       "4     94  17.4  20.5  20.4   8   8   7 -0.5000 -2.9544 -4.3301  114\n",
       "..   ...   ...   ...   ...  ..  ..  ..     ...     ...     ...  ...\n",
       "106   59  18.3  18.3  19.0   7   7   7 -3.9392 -1.9284 -1.7101   66\n",
       "107   70  17.1  18.2  18.0   7   7   7 -4.3301 -7.8785 -5.1962   72\n",
       "108   81  19.6  25.1  27.2   3   4   4 -1.9284 -2.5712 -4.3301   57\n",
       "109  146  27.0  32.7  33.7   0   0   0  2.9544  6.5778  4.3301  121\n",
       "110   78  17.7  20.2  21.5   5   5   3  0.0000  0.5209  0.0000   59\n",
       "\n",
       "[111 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ozone = pd.concat([ozone, ozone_new], ignore_index=True)\n",
    "ozone\n",
    "# We now have 111 rows (101 + 10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We now need to split ozone into two datasets : train and test with about 75% of ozone into train and 25% into test (randomly). There is a function that can do this automatically in the package sklearn : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train , test = train_test_split(ozone, test_size = 0.25) \n",
    "# just need to give the input dataset (ozone here) and the fraction that you want in the test set (25% here)\n",
    "# the two created datasets are called train and test as we have asked"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check that the dimensions of train and test are as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset dimensions: (83, 11)\n",
      "Test dataset dimensions: (28, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions of train and test datasets\n",
    "print(f\"Train dataset dimensions: {train.shape}\")\n",
    "print(f\"Test dataset dimensions: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To be able to compare the results that you will obtain with the ones that I have obtained, we need to have the \n",
    "same train / test split. For this, you can set a parameter 'random_state = 20' in the train_test_split function (I have also used random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train , test = train_test_split(ozone, test_size = 0.25, random_state = 20) \n",
    "# now we will use these train and test sets until the end of this TP (unless specified)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You can now easily estimate the generalization error of a regression model using the procedure shown in the CM:\n",
    " - fit a regression model with the train data (with predictive variables that you want)\n",
    " - predict using this model the individuals of the test set\n",
    " - compute the mean squared error of these predictions : it is the estimation of the generalization error\n",
    "Question : write a function 'generalization_error_split(train, test, idx_p, idx_t)' that estimates the generaliztion error by a train / test split procedure (with the train and test sets given in parameters) for a regression model that uses the variables in the columns of index idx_p to predict the target variable of index idx_t (in the datasets)\n",
    "Hint : with the functions my_regression and my_predictions above, it is quite easy\n",
    "Apply it to estimate the generalization error of a regression model that predicts y using x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5) What is the best single variable to predict y ? What is the estimation of the generalization error of such a model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6) Is the model using variables x2 and x3 better than the one using x2 only ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7) Is the model using all the variables (x1 to x10) better than the one using x2 only ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8) Is the model using variables x2, x4, x8, x10 better than the one using all the variables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The train/test split procedure is one way to estimate the generalization error of a regression model. One of its main drawback is that it is not very stable as it is really dependent on the random split. Two different splits might give very different estimations of the generalization error.\n",
    "A more stable way to estimate the generalization error is the K-fold cross validation procedure as explained in the CM. You will implement this a bit later during next TP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
